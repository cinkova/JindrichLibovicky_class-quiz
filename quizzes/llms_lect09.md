# Large Language Models: Lecture 9 Quiz (Multilinguality)

## Ability to solve a task in one language after fine-tuning or instructing in another language is attributed to:

1. Forced inference
2. (X) Cross-lingual transfer
3. Reinforcement learning from human feedback
4. Quantization

## Resourcefulness of a language is measured by:

1. (X) Availability of data
2. Number of speakers
3. Linguistics similarity to English
4. Number of unique characters in the writing script


## Which languages are the most prone to over-segmentation:

1. Low-resource, written with Latin script
2. High-resource, written with Latin script
3. (X) Low-resource, written with non-Latin script
4. High-resource, written with non-Latin script

## Which is true about using LLMs for machine translation:

1. Is only possible with GPT-4
2. (X) Can beat dedicated machine translation systems
3. Works better in translating from English than to English
4. Works only for high-resource languages
